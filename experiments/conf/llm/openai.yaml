_target_: "tomsutils.llm.OpenAILLM"
model_name: "gpt-4o-mini"
cache_dir:
  _target_: "pathlib.Path"
  _args_:
    - "llm_cache"
max_tokens: 700
use_cache_only: False
